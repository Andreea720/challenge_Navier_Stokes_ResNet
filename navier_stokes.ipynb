{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Estimation of Navier-Stokes equation\n",
    "## Done by: Andreea-Ioana Florea"
   ],
   "id": "bc05c451fa6e58e3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:40.892737300Z",
     "start_time": "2026-01-07T21:24:40.870132800Z"
    }
   },
   "source": "print(\"Hello, world!!!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!!!\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:40.910557300Z",
     "start_time": "2026-01-07T21:24:40.893839900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import deepxde as dde\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "ccaf0e0d0de4657d",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:40.976235Z",
     "start_time": "2026-01-07T21:24:40.926137900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Physical parameters\n",
    "rho = 1  # Density\n",
    "mu = 1   # Viscosity\n",
    "u_in = 1\n",
    "D = 1\n",
    "L = 2\n",
    "\n",
    "# Define geometry: A rectangle\n",
    "#geom = dde.geometry.Rectangle(xmin=[-L / 2, -D / 2], xmax=[L / 2, D / 2])\n",
    "# Main channel\n",
    "channel = dde.geometry.Rectangle(xmin=[-L / 2, -D / 2], xmax=[L / 2, D / 2])\n",
    "\n",
    "# Obstacle (Cylinder)\n",
    "center = [0, 0]\n",
    "radius = 0.1\n",
    "cylinder = dde.geometry.Disk(center, radius)\n",
    "\n",
    "# Combined geometry\n",
    "geom = channel - cylinder\n",
    "\n",
    "# 1. Define the Heart Shape coordinates\n",
    "t = np.linspace(0, 2 * np.pi, 100)\n",
    "# Parametric heart equations scaled down to size 0.1\n",
    "heart_x = 0.1 * (16 * np.sin(t)**3) / 16\n",
    "heart_y = 0.1 * (13 * np.cos(t) - 5 * np.cos(2*t) - 2 * np.cos(3*t) - np.cos(4*t)) / 16\n",
    "\n",
    "# Shift the heart to the LEFT of the center (x = -0.5)\n",
    "heart_points = np.vstack([heart_x - 0.5, heart_y]).T\n",
    "heart_shape = dde.geometry.Polygon(heart_points)\n",
    "\n",
    "# 2. Define the Cylinder and Channel\n",
    "channel = dde.geometry.Rectangle(xmin=[-L / 2, -D / 2], xmax=[L / 2, D / 2])\n",
    "cylinder = dde.geometry.Disk([0, 0], 0.1)\n",
    "\n",
    "# 3. Combine: Subtract BOTH from the channel\n",
    "# This creates a channel with two holes\n",
    "geom = channel - cylinder - heart_shape"
   ],
   "id": "919abd0973dd64a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\.conda\\envs\\challenge_Navier_Stokes_ResNet\\lib\\site-packages\\deepxde\\geometry\\geometry_2d.py:814: RuntimeWarning: invalid value encountered in divide\n",
      "  self.normal = self.normal / np.linalg.norm(self.normal, axis=1).reshape(-1, 1)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:41.001915100Z",
     "start_time": "2026-01-07T21:24:40.977237300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define boundary conditions\n",
    "def boundary_wall(X, on_boundary):\n",
    "    on_wall = np.logical_and(\n",
    "        np.logical_or(\n",
    "            np.isclose(X[1], -D / 2, rtol=1e-05, atol=1e-08),\n",
    "            np.isclose(X[1], D / 2, rtol=1e-05, atol=1e-08),\n",
    "        ),\n",
    "        on_boundary,\n",
    "    )\n",
    "    return on_wall\n",
    "\n",
    "def boundary_inlet(X, on_boundary):\n",
    "    on_inlet = np.logical_and(\n",
    "        np.isclose(X[0], -L / 2, rtol=1e-05, atol=1e-08), on_boundary\n",
    "    )\n",
    "    return on_inlet\n",
    "\n",
    "def boundary_outlet(X, on_boundary):\n",
    "    on_outlet = np.logical_and(\n",
    "        np.isclose(X[0], L / 2, rtol=1e-05, atol=1e-08), on_boundary\n",
    "    )\n",
    "    return on_outlet\n",
    "\n",
    "def boundary_cylinder(X, on_boundary):\n",
    "    # Check if the point is on the boundary and NOT on the outer channel walls\n",
    "    return on_boundary and not (\n",
    "        np.isclose(X[0], -L/2) or np.isclose(X[0], L/2) or\n",
    "        np.isclose(X[1], -D/2) or np.isclose(X[1], D/2)\n",
    "    )\n",
    "\n",
    "def boundary_obstacles(X, on_boundary):\n",
    "    # Logic: It's an obstacle if it's on a boundary but NOT the external box edges\n",
    "    on_outer_wall = np.logical_or(\n",
    "        np.logical_or(np.isclose(X[0], -L/2), np.isclose(X[0], L/2)),\n",
    "        np.logical_or(np.isclose(X[1], -D/2), np.isclose(X[1], D/2))\n",
    "    )\n",
    "    return on_boundary and not on_outer_wall\n",
    "\n",
    "# No-slip for all internal objects\n",
    "bc_obs_u = dde.DirichletBC(geom, lambda X: 0.0, boundary_obstacles, component=0)\n",
    "bc_obs_v = dde.DirichletBC(geom, lambda X: 0.0, boundary_obstacles, component=1)\n",
    "\n",
    "bc_cylinder_u = dde.DirichletBC(geom, lambda X: 0.0, boundary_cylinder, component=0)\n",
    "bc_cylinder_v = dde.DirichletBC(geom, lambda X: 0.0, boundary_cylinder, component=1)\n",
    "\n",
    "bc_wall_u = dde.DirichletBC(geom, lambda X: 0.0, boundary_wall, component=0)\n",
    "bc_wall_v = dde.DirichletBC(geom, lambda X: 0.0, boundary_wall, component=1)\n",
    "\n",
    "bc_inlet_u = dde.DirichletBC(geom, lambda X: u_in, boundary_inlet, component=0)\n",
    "bc_inlet_v = dde.DirichletBC(geom, lambda X: 0.0, boundary_inlet, component=1)\n",
    "\n",
    "bc_outlet_p = dde.DirichletBC(geom, lambda X: 0.0, boundary_outlet, component=2)\n",
    "bc_outlet_v = dde.DirichletBC(geom, lambda X: 0.0, boundary_outlet, component=1)"
   ],
   "id": "a29978b71db44978",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:41.017389900Z",
     "start_time": "2026-01-07T21:24:41.002920400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define PDE system\n",
    "def pde(X, Y):\n",
    "    \"\"\"Args:\n",
    "    Y: network output [u, v, p],\n",
    "    X: input coordinates [x, y]\"\"\"\n",
    "    du_x = dde.grad.jacobian(Y, X, i=0, j=0)\n",
    "    du_y = dde.grad.jacobian(Y, X, i=0, j=1)\n",
    "    dv_x = dde.grad.jacobian(Y, X, i=1, j=0)\n",
    "    dv_y = dde.grad.jacobian(Y, X, i=1, j=1)\n",
    "    dp_x = dde.grad.jacobian(Y, X, i=2, j=0)\n",
    "    dp_y = dde.grad.jacobian(Y, X, i=2, j=1)\n",
    "\n",
    "    du_xx = dde.grad.hessian(Y, X, component=0, i=0, j=0)\n",
    "    du_yy = dde.grad.hessian(Y, X, component=0, i=1, j=1)\n",
    "    dv_xx = dde.grad.hessian(Y, X, component=1, i=0, j=0)\n",
    "    dv_yy = dde.grad.hessian(Y, X, component=1, i=1, j=1)\n",
    "\n",
    "    pde_u = Y[:, 0:1] * du_x + Y[:, 1:2] * du_y + 1 / rho * dp_x - (mu / rho) * (du_xx + du_yy)\n",
    "    pde_v = Y[:, 0:1] * dv_x + Y[:, 1:2] * dv_y + 1 / rho * dp_y - (mu / rho) * (dv_xx + dv_yy)\n",
    "    pde_cont = du_x + dv_y\n",
    "\n",
    "\n",
    "    return [pde_u, pde_v, pde_cont]"
   ],
   "id": "2b0db88a37360a0d",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:41.033136300Z",
     "start_time": "2026-01-07T21:24:41.018894700Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b7084ac0a3592e7d",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:41.852688Z",
     "start_time": "2026-01-07T21:24:41.034147900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = dde.data.PDE(\n",
    "    geom,\n",
    "    pde,\n",
    "    [\n",
    "        bc_wall_u, bc_wall_v,\n",
    "        bc_inlet_u, bc_inlet_v,\n",
    "        bc_outlet_p, bc_outlet_v,\n",
    "        bc_obs_u, bc_obs_v  # Applies to both Heart and Cylinder\n",
    "    ],\n",
    "    num_domain=3000,    # Increase domain points for more detail\n",
    "    num_boundary=600,   # Increase boundary points to define the heart edges\n",
    "    num_test=200,\n",
    ")"
   ],
   "id": "ac940ca8d3bf23e2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\.conda\\envs\\challenge_Navier_Stokes_ResNet\\lib\\site-packages\\deepxde\\geometry\\geometry_2d.py:920: RuntimeWarning: invalid value encountered in divide\n",
      "  v = (self.vertices[i + 1] - self.vertices[i]) / self.diagonals[i, i + 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: CSGDifference.uniform_points not implemented. Use random_points instead.\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-07T21:24:41.894879500Z",
     "start_time": "2026-01-07T21:24:41.877782400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define neural network\n",
    "net = dde.maps.FNN([2] + [64] * 5 + [3], \"tanh\", \"Glorot uniform\")\n",
    "model = dde.Model(data, net)"
   ],
   "id": "188ec69f26a638be",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-01-07T21:24:41.896079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile and train\n",
    "model.compile(\"adam\", lr=1e-3)\n",
    "losshistory, train_state = model.train(epochs=20000)"
   ],
   "id": "6c55b8d5fe0a472e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling model...\n",
      "'compile' took 0.002389 s\n",
      "\n",
      "Warning: epochs is deprecated and will be removed in a future version. Use iterations instead.\n",
      "Training model...\n",
      "\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F030401FC0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F030401FC0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F030401FC0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F030401FC0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A820790> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820790>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A820790> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820790>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A820AF0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820AF0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A820AF0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820AF0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A820E50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820E50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A820E50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820E50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A8211B0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A8211B0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A8211B0> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A8211B0>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A821510> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A821510>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A821510> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A821510>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A803B50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A803B50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A803B50> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A803B50>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x000002F09A820160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820160>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x000002F09A820160> and will run it as-is.\n",
      "Cause: could not parse the source code of <function <lambda> at 0x000002F09A820160>: no matching AST found among candidates:\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary1(x[i], on[i]) for i in range(len(x))])\n",
      "# coding=utf-8\n",
      "lambda x, on: np.array([on_boundary2(x[i], on[i]) for i in range(len(x))])\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Step      Train loss                                                                                                        Test loss                                                                                                         Test metric\n",
      "0         [2.06e-02, 6.34e-03, 4.92e-02, 3.74e-03, 1.46e-02, 1.04e+00, 3.15e-03, 2.02e-02, 4.95e-03, 8.47e-05, 7.38e-04]    [1.95e-02, 7.01e-03, 4.80e-02, 3.74e-03, 1.46e-02, 1.04e+00, 3.15e-03, 2.02e-02, 4.95e-03, 8.47e-05, 7.38e-04]    []  \n",
      "1000      [1.05e-03, 1.73e-03, 3.54e-02, 1.50e-02, 3.36e-02, 4.73e-02, 2.31e-02, 1.78e-04, 9.50e-05, 4.22e-02, 1.27e-03]    [1.17e-03, 2.30e-03, 4.15e-02, 1.50e-02, 3.36e-02, 4.73e-02, 2.31e-02, 1.78e-04, 9.50e-05, 4.22e-02, 1.27e-03]    []  \n",
      "2000      [1.84e-03, 3.35e-03, 2.64e-02, 9.28e-03, 3.93e-02, 4.29e-02, 1.08e-02, 1.42e-05, 1.51e-06, 3.48e-02, 2.00e-03]    [1.93e-03, 7.05e-03, 3.56e-02, 9.28e-03, 3.93e-02, 4.29e-02, 1.08e-02, 1.42e-05, 1.51e-06, 3.48e-02, 2.00e-03]    []  \n",
      "3000      [6.77e-03, 1.69e-03, 2.23e-02, 7.35e-03, 4.31e-02, 3.58e-02, 6.85e-03, 3.38e-04, 9.65e-06, 3.26e-02, 2.46e-03]    [9.98e-03, 2.66e-03, 3.15e-02, 7.35e-03, 4.31e-02, 3.58e-02, 6.85e-03, 3.38e-04, 9.65e-06, 3.26e-02, 2.46e-03]    []  \n",
      "4000      [1.28e-03, 6.08e-04, 2.15e-02, 5.56e-03, 4.63e-02, 3.31e-02, 3.72e-03, 5.04e-05, 1.33e-05, 2.82e-02, 2.78e-03]    [1.83e-03, 6.63e-04, 3.04e-02, 5.56e-03, 4.63e-02, 3.31e-02, 3.72e-03, 5.04e-05, 1.33e-05, 2.82e-02, 2.78e-03]    []  \n",
      "5000      [3.46e-03, 2.60e-03, 1.99e-02, 4.94e-03, 4.77e-02, 3.22e-02, 3.28e-03, 4.30e-05, 1.54e-05, 2.57e-02, 2.79e-03]    [6.08e-03, 4.27e-03, 2.78e-02, 4.94e-03, 4.77e-02, 3.22e-02, 3.28e-03, 4.30e-05, 1.54e-05, 2.57e-02, 2.79e-03]    []  \n",
      "6000      [5.00e-03, 6.76e-03, 1.84e-02, 4.93e-03, 4.92e-02, 3.05e-02, 3.20e-03, 1.48e-04, 1.87e-05, 2.40e-02, 2.79e-03]    [1.25e-02, 1.01e-02, 2.51e-02, 4.93e-03, 4.92e-02, 3.05e-02, 3.20e-03, 1.48e-04, 1.87e-05, 2.40e-02, 2.79e-03]    []  \n",
      "7000      [7.03e-03, 1.82e-03, 1.68e-02, 4.21e-03, 4.95e-02, 3.09e-02, 2.53e-03, 3.55e-04, 1.84e-05, 2.31e-02, 2.94e-03]    [2.00e-02, 4.05e-03, 2.27e-02, 4.21e-03, 4.95e-02, 3.09e-02, 2.53e-03, 3.55e-04, 1.84e-05, 2.31e-02, 2.94e-03]    []  \n",
      "8000      [1.94e-02, 7.57e-03, 1.55e-02, 4.11e-03, 5.00e-02, 3.01e-02, 2.62e-03, 1.32e-03, 2.64e-05, 2.32e-02, 2.96e-03]    [2.75e-02, 1.46e-02, 2.07e-02, 4.11e-03, 5.00e-02, 3.01e-02, 2.62e-03, 1.32e-03, 2.64e-05, 2.32e-02, 2.96e-03]    []  \n",
      "9000      [3.31e-03, 1.85e-03, 1.71e-02, 3.93e-03, 5.01e-02, 2.92e-02, 2.00e-03, 1.30e-05, 1.35e-05, 2.11e-02, 3.07e-03]    [8.89e-03, 2.94e-03, 2.29e-02, 3.93e-03, 5.01e-02, 2.92e-02, 2.00e-03, 1.30e-05, 1.35e-05, 2.11e-02, 3.07e-03]    []  \n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize training points\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(data.train_x_all[:, 0], data.train_x_all[:, 1], s=0.5)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()\n",
    "\n",
    "# Predict and plot results\n",
    "samples = geom.random_points(500000)\n",
    "result = model.predict(samples)\n",
    "\n",
    "color_legend = [[0, 1.5], [-0.3, 0.3], [0, 35]]\n",
    "for idx in range(3):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.scatter(samples[:, 0], samples[:, 1], c=result[:, idx], cmap=\"jet\", s=2)\n",
    "    plt.colorbar()\n",
    "    plt.clim(color_legend[idx])\n",
    "    plt.xlim((0 - L / 2, L - L / 2))\n",
    "    plt.ylim((0 - D / 2, D - D / 2))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "c858d1fb339421cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "num_frames = 150\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "\n",
    "# Reuse the same samples\n",
    "samples = geom.random_points(300000)\n",
    "\n",
    "for i in range(num_frames):\n",
    "    result = model.predict(samples)\n",
    "\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.scatter(\n",
    "        samples[:, 0],\n",
    "        samples[:, 1],\n",
    "        c=result[:, 0],   # u-velocity (change to 1 or 2 if needed)\n",
    "        cmap=\"jet\",\n",
    "        s=2\n",
    "    )\n",
    "    plt.colorbar()\n",
    "    plt.clim(0, 1.5)\n",
    "    plt.xlim((-L / 2, L / 2))\n",
    "    plt.ylim((-D / 2, D / 2))\n",
    "    plt.title(f\"Frame {i+1}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(f\"frames/frame_{i:04d}.png\", dpi=150)\n",
    "    plt.close()\n"
   ],
   "id": "c0df4d690b0a4390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fdf0d17ddd519770",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "af5dc546ee0c5c05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
